下载spark2.0：http://www.aboutyun.com/forum.php?mod=viewthread&tid=26432&ordertype=1

Spark部署方式
1、Local模式
    Local模式就是运行在一台计算机上的模式，通常就是用于在本机上练手和测试。它可以通过以下集中方式设置master。

    local: 所有计算都运行在一个线程当中，没有任何并行计算，通常我们在本机执行一些测试代码，或者练手，就用这种模式。
    local[K]: 指定使用几个线程来运行计算，比如local[4]就是运行4个worker线程。通常我们的cpu有几个core，就指定几个线程，最大化利用cpu的计算能力
    local[*]: 这种模式直接帮你按照cpu最多cores来设置线程数了。
2、cluster模式
    分为以下三种模式，区别在于谁去管理资源调度。
    1、standalone模式
    这种模式下，Spark会自己负责资源的管理调度。它将cluster中的机器分为master机器和worker机器，master通常就一个，
    可以简单的理解为那个后勤管家，worker就是负责干计算任务活的苦劳力。
    2、mesos模式
    3、yarn模式
    由于很多时候我们需要和mapreduce使用同一个集群，所以都采用Yarn来管理资源调度，这也是生产环境大多采用yarn模式的原因。
    yarn模式又分为yarn cluster模式和yarn client模式：

    yarn cluster: 这个就是生产环境常用的模式，所有的资源调度和计算都在集群环境上运行。
    yarn client: 这个是说Spark Driver和ApplicationMaster进程均在本机运行，而计算任务在cluster上。
3、DataSet\DataFrame\RDD的区别：
  （1）相同点：
            都是分布式数据集
            DataFrame底层是RDD，但是DataSet不是，不过他们最后都是转换成RDD运行
            DataSet和DataFrame的相同点都是有数据特征、数据类型的分布式数据集(schema)
  （2）不同点：
            （a）schema信息：
                  RDD中的数据是没有数据类型的
                  DataFrame中的数据是弱数据类型，不会做数据类型检查
                      虽然有schema规定了数据类型，但是编译时是不会报错的，运行时才会报错
                  DataSet中的数据类型是强数据类型
            （b）序列化机制：
                  RDD和DataFrame默认的序列化机制是java的序列化，可以修改为Kyro的机制
                  DataSet使用自定义的数据编码器进行序列化和反序列化

4、 DataSet\DataFrame\RDD的相互转化
    1、要使用toDS之前
      import sqlContext.implicits._
    2、将内存中的数据转换成DataSet
        sqlContext.implicits._
        val ds = Seq(1, 2, 3).toDS()
        ds.map(_ + 1).collect() // Returns: Array(2, 3, 4)

        其中：
        collect()：返回一个Array，包含所有行信息
        Returns an array that contains all rows in this Dataset.