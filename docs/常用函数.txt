0、小型
    fit()：调用fit来训练一个模型。
1、scala中mkstring
    scala通过mkString方法把一个集合转化为一个字符串
2、spark中map and flatMap
    val lineArray = Array("hello you","hello me","hello world")
    val lines = sc.parallelize(lineArray, 1)
    val words = lines.flatMap(line =>{ line.split(" ") })
    words.foreach {
      word => println(word.mkString)
    }
    其中：map的结果为。
    helloyou
    hellome
    helloworld

    flatmap的结果为
    hello
    you
    hello
    me
    hello
    world

    也就是说：map和flatmap会对【集合中的元素】【执行函数中的操作】，
    map：操作之后【一个元素还是一个元素】。将生成的各个元素合并成一个元素。
    flatMap：操作之后会【一个元素变成多个元素】。将生成的子元素分别放在了当前的集合。

3、如何将海量字符串映射为数字——
    StringIndexer & IndexToString

    //将两组数组成一个DataFrame，给出列名"id","category"
    val df = sqlContext.createDataFrame(
      Seq((0,"a"),(1,"b"),(2,"c"),(3,"a"),(4,"a"),(5,"c"))
    ).toDF("id","category")

    //创建一个StringIndexer，设置输入列为"category"，输出列为"categoryIndex"
    val indexer =newStringIndexer()
      .setInputCol("category")
      .setOutputCol("categoryIndex")

    //？？？

    val indexed = indexer.fit(df).transform(df)
    indexed.show()

4、spark中的 withColumn
    使用withColumn函数增加列： withColumn函数一次只能增加一个列。
    spark源码里有withColumns函数可以一次增加多列，但是并未开放，希望将来能开放出来。
    data.withColumn(colName, data.col(colName).cast(DoubleType))
    第一个参数是展示列的名称，第二个参数：data.col()：获取列的名对应的值，cast：转化类型。
5、dataFrame中常用方法
    参考：https://blog.csdn.net/chuan403082010/article/details/85163011

    1、删除dataframe列
    df.drop(columns=["instant","dteday"])

    2、修改dataframe列名
    暴力
    a.columns = ['a','b','c']

    较好的方法
    a.rename(columns={'A':'a', 'B':'b', 'C':'c'}, inplace = True)

    3、查看dataframe字段信息
      a.info()

    4、修改dataframe列类型

      df["instant"] = df["instant"].astype("object")
      X[['Global_active_power',"b"]] = X[['Global_active_power',"b"]].astype('float64')












