1、检查点机制（详解在下面）

    检查点机制是我们在 Spark Streaming 中用来保障容错性的主要机制。
    它可以使 Spark Streaming 阶段性地把应用数据存储到诸如 HDFS 或 Amazon S3 这样的可靠存储系统中，以供恢复时使用
    检查点机制主要为以下两个目的服务
        • 控制发生失败时需要重算的状态数。我们在 10.2 节中讨论过，Spark Streaming 可以通
        过转化图的谱系图来重算状态，检查点机制则可以控制需要在转化图中回溯多远。
        • 提供驱动器程序容错。如果流计算应用中的驱动器程序崩溃了，你可以重启驱动器程序 并让驱动器程序从检查点恢复，
        这样 Spark Streaming 就可以读取之前运行的程序处理    数据的进度，并从那里继续。

    通过向ssc.checkpoint() 方法传递一个路径参数（HDFS、S3 或者本地路径均可）来配置检查点机制
    ssc.checkpoint("hdfs://...")

    即便是在本地模式下，如果你尝试运行一个有状态操作而没有打开检查点机制，Spark Streaming 也会给出提示

2、驱动器程序容错
    1、我们需要把检查点 目 录 提 供 给 StreamingContext。
        与 直 接 调 用 new StreamingContext 不 同， 应 该 使 用StreamingContext.getOrCreate() 函数。

        def createStreamingContext() = {
         ...
         val sc = new SparkContext(conf)
         // 以1秒作为批次大小创建StreamingContext
         val ssc = new StreamingContext(sc, Seconds(1))
         ssc.checkpoint(checkpointDir)
        }
        ...
        val ssc = StreamingContext.getOrCreate(checkpointDir, createStreamingContext _)

        设置了检查点：假设目录不存在，会在你调用时把目录创建出来。
        在驱动器程序失败之后，getOrCreate()会重新从检查点目录中初始化出StreamingContext，然后继续处理。

    2、还需要编写在驱动器程序崩溃时重启驱 动器进程的代码。
    在大多数集群管理器中，Spark 不会在驱动器程序崩溃时自动重启驱动器进程。
        使用监管模式启动驱动器程序：
       ./bin/spark-submit --deploy-mode cluster --supervise --master spark://... App.jar

3、工作节点容错
    所有从外部数据源中收到的数据都在多个工作节点上备份。
    所有从备份数据转化操作的过程中创建出来的 RDD 都能容忍一个工作节点的失败

4、接收器容错
    所有从可靠文件系统中读取的数据（比如通过 StreamingContext.hadoopFiles 读取的）都是可靠的，因为底层的文件系统是有备份的。
    Spark Streaming 会记住哪些数据存放到了检查点中，并在应用崩溃后从检查点处继续执行。

    对于像 Kafka、推式 Flume、Twitter 这样的不可靠数据源，spark1.2中 收到的数据被记录到诸
    如 HDFS 这样的可靠的文件系统中，这样即使驱动器程序重启也不会导致数据丢失。

    综上所述，确保所有数据都被处理的最佳方式是使用可靠的数据。

5、处理保证
=======================================================================================
检查点机制详解：
    参考文档：https://www.cnblogs.com/tongxupeng/p/10439889.html

    1、cache和checkpoint的区别：
    缓存（cache）把 RDD 计算出来然后放在内存中，但是RDD 的依赖链 也不能丢掉，
    当某个点某个 executor 宕了，上面cache 的RDD就会丢掉，需要通过依赖链重放计算出来。

    不同的是，checkpoint是把 RDD 保存在 HDFS中， 是多副本可靠存储，
    所以依赖链就可以丢掉了，就斩断了依赖链， 是通过复制实现的高容错。

    我的总结，cache保存在内存中，依赖链不能丢掉。 checkpoint 把rdd 保存在hdfs中，可以丢掉依赖链。
    其实就是将某个Rdd保存在磁盘上，所有的依赖关系不复存在。

    checkpoint是转化操作，在action的时候才会执行。

    2、总结：
    checkpoint 的机制保证了需要访问重复数据的应用 【Spark 的DAG执行行图可能很庞大，task 中计算链可能会很长】，
    这时如果 task 中途运行出错，那么 task 的整个需要重算非常耗时，有必要将计算代价较大的 RDD checkpoint 一下

    当下游 RDD 计算出错时，可以直接从 checkpoint 过的 RDD 那里读取数据继续算。

























