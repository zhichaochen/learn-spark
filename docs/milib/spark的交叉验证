1、Spark中采用是k折交叉验证 （k-fold cross validation）。
    例如10折交叉验证(10-fold cross validation)，将数据集分成10份，轮流将其中9份做训练1份做验证，
    10次的结果的均值作为对算法精度的估计。

    10折交叉检验最常见，是因为通过利用大量数据集、使用不同学习技术进行的大量试验，表明10折是获得最好误差估计的恰当选择，
    但这并非最终结论，争议仍然存在。而且似乎5折或者20折与10折所得出的结果也相差无几。

    交叉检验常用于分析模型的泛化能力，提高模型的稳定

    在Spark中，Cross Validation和ParamMap（“参数组合”的Map）结合使用。
    具体做法是，针对某有特定的Param组合，CrossValidator计算K （K 折交叉验证）个评估分数的平均值。
    然后和其它“参数组合”CrossValidator计算结果比较，完成所有的比较后，将最优的“参数组合”挑选出来，
    这“最优的一组参数”将用在整个训练数据集上重新训练(re-fit)，得到最终的Model。

    也就是说，通过交叉验证，找到了最佳的”参数组合“，利用这组参数，在整个训练集上可以训练（fit）出一个泛化能力强，
    误差相对最小的的最佳模型。

    很显然，交叉验证计算代价很高，假设有三个参数：参数alpha有3中选择，参数beta有4种选择，参数gamma有4中选择，
    进行10折计算，那么将进行（3×4×4）×10=480次模型训练。






















